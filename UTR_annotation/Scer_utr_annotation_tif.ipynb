{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reannotates S. cerevisiae gff using empirically discovered 3'UTRs from Pelechano et al 2013. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gffutils\n",
    "import copy\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't think I use these at all\n",
    "# #these functions change the text in the attributes column after assigning a parent/child\n",
    "# #relationship in a gffutils database. \n",
    "# def parent_func(parent, child):\n",
    "#     #print('parent_func(%r, %r)' % (parent, child))\n",
    "#     parent.attributes['child'] = child.id\n",
    "    \n",
    "#     return parent\n",
    "    \n",
    "# def child_func(parent, child):\n",
    "#     #print('child_func(%r, %r)' % (parent, child))\n",
    "#     child.attributes['Parent'] = parent.id\n",
    "    \n",
    "#     return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load original gff data and establish basis for filenames and directory for files.\n",
    "genome_assy_dir = os.path.normpath(\"/home/heineike/genomes/scer_20181114\")\n",
    "#os.path.normpath('C:\\\\Users\\\\BMH_work\\\\Google Drive\\\\UCSF\\\\ElSamad_Lab\\\\PKA\\\\Bioinformatics\\\\genome_assembly')\n",
    "\n",
    "sc_ref_base = 'saccharomyces_cerevisiae_R64-2-1_20150113' #'scer_ref_test'\n",
    "sc_ref_fn = genome_assy_dir + os.sep + sc_ref_base + '.gff'\n",
    "\n",
    "#utr3p_fn = genome_assy_dir + os.sep + 'Nagalakshmi_2008_3UTRs_V64.gff3'#' Nag_gff_test'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up original Scer alignment file\n",
    "\n",
    "1. By uploading via gffutils and printing again, replaces %20 with spaces, and other formatting.  Also only prints features, not sequences\n",
    "2. Change chromosome name to roman numerals which work better with the genome used by bluebee (I presume that it is from Ensembl?)\n",
    "3. Replace B\" with Bprimeprime in YNL039W\n",
    "4. For features with duplicates (which are of the following featuretypes: ['CDS', 'intron', 'noncoding_exon', 'internal_transcribed_spacer_region', 'external_transcribed_spacer_region'], replaces names with serialized version.  E.g. YLR157C-B_CDS.1 and YLR157C-B_CDS.2.   \n",
    "5. For those types of features makes ID equal to the name (after making sure Names are unique in step 4).  \n",
    "\n",
    "Reprints file as : \n",
    "\n",
    "saccharomyces_cerevisiae_R64-2-1_20150113_unique_ids.gff\n",
    "\n",
    "\n",
    "\n",
    "#Note: Originally, Two lines have the exact same region and were merged when updating the database.  Changed update to key on ID or Name and that seemed to fix it. \n",
    "\n",
    "#around this line: 14758\n",
    "#XII\tSGD\texternal_transcribed_spacer_region\t451575\t451785\t.\t-\t.\tdbxref=SGD:S000029718;Parent=ETS2-1;Name=ETS2-1_external_transcribed_spacer_region\n",
    "#XII\tSGD\texternal_transcribed_spacer_region\t451575\t451785\t.\t-\t.\tdbxref=SGD:S000006486;Parent=RDN37-1;Name=RDN37-1_external_transcribed_spacer_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the original gff as a database\n",
    "\n",
    "#when troubleshooting you may need to close the database before remaking it. \n",
    "orig_gff_db.conn.close()\n",
    "\n",
    "orig_gff_db_fn = genome_assy_dir+os.sep + sc_ref_base + '.gff'\n",
    "\n",
    "dbfn=genome_assy_dir + os.sep + sc_ref_base + '_orig.db'\n",
    "\n",
    "orig_gff_db = gffutils.create_db(orig_gff_db_fn, dbfn=dbfn, \n",
    "                                 force=True, \n",
    "                                 #keep_order=True,\n",
    "                                 #sort_attribute_values=True\n",
    "                                 merge_strategy='error')\n",
    "\n",
    "#If you don't want to recreate the database, you can load it from the file.\n",
    "#orig_gff_db = gffutils.FeatureDB(dbfn) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Chromosome name: chrI.  New Chromosome name: I\n",
      "Old Chromosome name: chrII.  New Chromosome name: II\n",
      "Old Chromosome name: chrIII.  New Chromosome name: III\n",
      "Old Chromosome name: chrIV.  New Chromosome name: IV\n",
      "Old Chromosome name: chrV.  New Chromosome name: V\n",
      "Old Chromosome name: chrVI.  New Chromosome name: VI\n",
      "Old Chromosome name: chrVII.  New Chromosome name: VII\n",
      "Old Chromosome name: chrVIII.  New Chromosome name: VIII\n",
      "Old Chromosome name: chrIX.  New Chromosome name: IX\n",
      "Old Chromosome name: chrX.  New Chromosome name: X\n",
      "Old Chromosome name: chrXI.  New Chromosome name: XI\n",
      "Old Chromosome name: chrXII.  New Chromosome name: XII\n",
      "Old Chromosome name: chrXIII.  New Chromosome name: XIII\n",
      "Old Chromosome name: chrXIV.  New Chromosome name: XIV\n",
      "Old Chromosome name: chrXV.  New Chromosome name: XV\n",
      "Old Chromosome name: chrXVI.  New Chromosome name: XVI\n",
      "Old Chromosome name: chrmt.  New Chromosome name: Mito\n"
     ]
    }
   ],
   "source": [
    "#renames all chromosomes to match the name that the SAM files from lexogen use. \n",
    "\n",
    "roman_numerals = ['I','II','III','IV','V','VI','VII','VIII','IX','X','XI','XII','XIII','XIV','XV','XVI']\n",
    "chromosome_rename_dict = {'chr' + num : num for num in roman_numerals} \n",
    "chromosome_rename_dict['chrmt']='Mito'\n",
    "\n",
    "for old_chr, new_chr in chromosome_rename_dict.items():\n",
    "    print('Old Chromosome name: ' + old_chr + '.  New Chromosome name: ' + new_chr)\n",
    "    orig_gff_db.execute(\"update features set seqid='{}' where seqid='{}'\".format(new_chr, old_chr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gffutils.interface.FeatureDB at 0x7fc648bed9b0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removed an open quote that was contained in line 18642:\n",
    "#line = 'XIV\tSGD\tgene\t555048\t556832\t.\t+\t.\tID=YNL039W;dbxref=SGD:S000004984;Name=YNL039W;Note=Essential subunit of RNA polymerase III transcription factor (TFIIIB)%3B TFIIIB is involved in transcription of genes encoding tRNAs%2C 5S rRNA%2C U6 snRNA%2C and other small RNAs;display=Essential subunit of RNA polymerase III transcription factor (TFIIIB);Ontology_term=GO:0000126,GO:0001026,GO:0001112,GO:0001156,GO:0070896,GO:0070898;orf_classification=Verified;gene=BDP1;Alias=B\",BDP1,TFC5,TFC7,TFIIIB90,transcription factor TFIIIB subunit BDP1'\n",
    "#YNL039W, BDP1 changed B\" alias to Bprimeprime\n",
    "\n",
    "feature = orig_gff_db['YNL039W']\n",
    "att_dict = dict(feature.attributes)\n",
    "\n",
    "new_alias_list = []\n",
    "for alias in att_dict['Alias']: \n",
    "    if alias=='B\"':\n",
    "        new_alias_list.append('Bprimeprime')\n",
    "    else: \n",
    "        new_alias_list.append(alias)\n",
    "\n",
    "feature['Alias'] = new_alias_list\n",
    "\n",
    "orig_gff_db.delete(feature.id, merge_strategy='error')\n",
    "orig_gff_db.update([feature],\n",
    "                   #id_spec = ['ID','Name'],\n",
    "                   merge_strategy='error')\n",
    "\n",
    "\n",
    "#Can also do line by line in the GFF\n",
    "# with open(genome_assy_dir+os.sep + sc_ref_base + '_chr_rename.gff', 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# with open(genome_assy_dir+os.sep + sc_ref_base + '_chr_rename.gff', 'w') as f:\n",
    "#     for line in lines:\n",
    "#         if 'Alias=B\"' in line:\n",
    "#             line_split = line.split('Alias=B\"')\n",
    "#             line = line_split[0] + 'Alias=Bprimeprime' + line_split[1]\n",
    "#         f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print to intermediate file.  \n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_chr_rename.gff', 'w') as outfile:\n",
    "    outfile.write('##gff-version 3\\n')\n",
    "    for feature in orig_gff_db.all_features(order_by = ('seqid','start','featuretype')):\n",
    "         print(feature,file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning duplicate Names\n",
      "Duplicated Names cleaned\n",
      "Assigning ID as name for the following featuretypes:\n",
      "['CDS', 'intron', 'noncoding_exon', 'internal_transcribed_spacer_region', 'external_transcribed_spacer_region']\n",
      "IDs assigned to features\n"
     ]
    }
   ],
   "source": [
    "#Identifies line items with duplicate names and replaces those with serialized names\n",
    "\n",
    "\n",
    "#Make list of all IDs.  If no ID, stores tuple with (No_ID, <feature_type>, <Name>)\n",
    "ids = []\n",
    "\n",
    "df = pd.read_table(genome_assy_dir+os.sep + sc_ref_base + '_chr_rename.gff', skiprows=1,header=None)\n",
    "\n",
    "for ind,row in df.iterrows():\n",
    "    feature_type = row[2]\n",
    "    attribs = row[8].split(';')\n",
    "    \n",
    "    att_dict = {}\n",
    "    id_found = False\n",
    "    for att in attribs: \n",
    "        att_type,att_val = att.split('=')\n",
    "        att_dict[att_type] = att_val\n",
    "        if att_type == 'ID':\n",
    "            ids.append(att_val)\n",
    "            id_found = True\n",
    "    if id_found==False:\n",
    "        if 'Name' in att_dict.keys():\n",
    "            ids.append(('No_ID',feature_type,att_dict['Name']))\n",
    "        else: \n",
    "            ids.append( 'No ID attribute. Type = ' + feature_type + '.  Other options: ' + str(att_dict))\n",
    "            raise ValueError(\"No ID or Name\")\n",
    "\n",
    "ids_counter = Counter(ids)\n",
    "\n",
    "#Makes list of tuples that represent all duplicated items in the dataset.  \n",
    "dupe_items = []\n",
    "for item in ids_counter.items():\n",
    "    if item[1]>1:\n",
    "        dupe_items.append(item)\n",
    "\n",
    "        \n",
    "\n",
    "#Cycle through duplicated items, set Names equal to new names\n",
    "print('Cleaning duplicate Names')\n",
    "features_to_update = []\n",
    "features_to_remove = []\n",
    "for ((noid, featuretype, name),NN) in dupe_items: \n",
    "    #Finds features in database that have matching Name attributes\n",
    "    cursor = orig_gff_db.execute(\"SELECT * FROM features WHERE featuretype='\" + featuretype + \"' AND attributes LIKE '%\\\"Name\\\":[\\\"\" + name + \"\\\"]%'\")\n",
    "    found_features = cursor.fetchall()\n",
    "    assert len(found_features)==NN, \"More features found than in duplicate items list\"\n",
    "    \n",
    "    #sort features with matching names by start position\n",
    "    id_start_list = []\n",
    "    for found_feature in found_features: \n",
    "        id_start_list.append((found_feature['id'], found_feature['start']))\n",
    "    id_start_list_sorted = sorted(id_start_list, key = lambda x: x[1])\n",
    "    \n",
    "    for jj, (old_id, start) in enumerate(id_start_list_sorted): \n",
    "        found_feature = orig_gff_db[old_id]\n",
    "        features_to_remove.append(orig_gff_db[old_id])\n",
    "        new_name = found_feature['Name'][0] + '.{}'.format(jj+1) \n",
    "        #found_feature['ID']=new_name  all features of selected types will have ID set to name next\n",
    "        found_feature['Name']=new_name\n",
    "        features_to_update.append(found_feature)\n",
    "    #orig_gff_db.conn.commit()\n",
    "\n",
    "orig_gff_db.delete(features_to_remove, merge_strategy='error')\n",
    "orig_gff_db.update(features_to_update, merge_strategy='error', id_spec = ['ID','Name'])\n",
    "    \n",
    "print('Duplicated Names cleaned')\n",
    "\n",
    "#cycle through all featuretypes that had duplicate Names assigned, assign the Name field as the ID\n",
    "#Could do this for all fields that don't have an ID. \n",
    "\n",
    "print('Assigning ID as name for the following featuretypes:')\n",
    "\n",
    "featuretypes_to_assign_ids = ['CDS', 'intron', 'noncoding_exon', 'internal_transcribed_spacer_region', 'external_transcribed_spacer_region']\n",
    "\n",
    "print(featuretypes_to_assign_ids)\n",
    "\n",
    "\n",
    "features_to_update = []\n",
    "features_to_remove = []\n",
    "for featuretype in featuretypes_to_assign_ids: \n",
    "    for feature in orig_gff_db.features_of_type(featuretype):\n",
    "        features_to_remove.append(orig_gff_db[feature.id])\n",
    "        feature['ID']=feature['Name'] \n",
    "        features_to_update.append(feature)\n",
    "\n",
    "orig_gff_db.delete(features_to_remove, merge_strategy='error')\n",
    "orig_gff_db.update(features_to_update, merge_strategy='error', id_spec = ['ID','Name'])\n",
    "\n",
    "print('IDs assigned to features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing dubious orfs\n",
      "Dubious orfs removed.  List saved at /home/heineike/genomes/scer_20181114/dubious_orfs_removed\n"
     ]
    }
   ],
   "source": [
    "#remove dubious orfs\n",
    "#How many?\n",
    "#From searching classification=Dubious and dividing by two (one for CDS and one for Gene) we get \n",
    "#1574/2 = 787\n",
    "#There are 784 genes that have orf_classification of dubious, and 787 CDS that do.  I wonder what the other ones are. \n",
    "\n",
    "\n",
    "dub_orf_list = []\n",
    "features_to_remove = []\n",
    "\n",
    "for gene in orig_gff_db.features_of_type('gene'):\n",
    "    if gene.attributes['orf_classification'][0]=='Dubious':\n",
    "        features_to_remove = features_to_remove + [gene] + list(orig_gff_db.children(gene.id))\n",
    "        dub_orf_list.append(gene.id)\n",
    "\n",
    "\n",
    "print('Removing dubious orfs')\n",
    "orig_gff_db.delete(features_to_remove, merge_strategy='error')\n",
    "duborf_fn = genome_assy_dir+os.sep + 'dubious_orfs_removed'\n",
    "print('Dubious orfs removed.  List saved at ' + duborf_fn)\n",
    "with open(duborf_fn, 'w') as f:\n",
    "    for line in dub_orf_list:\n",
    "        f.write(line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print to file\n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_unique_ids.gff', 'w') as outfile:\n",
    "    outfile.write('##gff-version 3\\n')\n",
    "    for feature in orig_gff_db.all_features(order_by = ('seqid','start','featuretype')): \n",
    "        \n",
    "        print(feature,file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the file looks good, close and commit\n",
    "orig_gff_db.conn.commit()\n",
    "orig_gff_db.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of 784 dubious orfs, there were 176 dubious orfs that had a full orf transcript in ypd and 181 that had a full orf transcript in gal (233 in either gal or YPD).  See dubious_orfs_with_tifs.gff for list.    \n",
    "\n",
    "examples: \n",
    "YDL187C had many full orf transcripts.  \n",
    "YDL114W-A only had two and was right next to YDL115W\n",
    "YBR099C might be part of YBR101C's 3' UTR for long transcript isoforms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 dubious orfs with a tif covering the whole orf in either gal or YPD.\n"
     ]
    }
   ],
   "source": [
    "duborf_fn = genome_assy_dir+os.sep + 'dubious_orfs_with_tifs.gff'\n",
    "duborf_tif = pd.read_table(duborf_fn, header=None)\n",
    "genelist = []\n",
    "for ind, row in duborf_tif.iterrows():\n",
    "    genename = row[8].split(';')[0].split('=')[1].split('.')[0]\n",
    "    genelist.append(genename)\n",
    "\n",
    "print(\"{} dubious orfs with a tif covering the whole orf in either gal or YPD.\".format(len(set(genelist))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Transcript annotation to SGD annotation file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First set limits for transcripts based on genome architecture. \n",
    "\n",
    "#Build a dictionary linking each gene to the max extent of its 3'UTR, which we define as the beginning of the \n",
    "#next non-overlapping ORF\n",
    "\n",
    "#Make a list of orfs that are subsets of other ORFs.  These will be combined and reads assigned to the longest ORF. \n",
    "\n",
    "#Make a list of orfs that overlap.  Transcripts that overlap both orfs will be assigned to the one with the furthest 3' end \n",
    "#(i.e. if on the + strand where end is greatest and if on the - strand where start is greatest)\n",
    "#Reads that align to the CDS+3'UTR of the one with the furthest 3'end will be assigned to that gene, even if they also are assigned\n",
    "#to the other overlapped orf.  The only reads that will be assigned to the overlapped ORF will be part of the CDS of that orf \n",
    "#that does not overlap.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "#For metadata at the beginning of the file: \n",
    "#Note=max extent of longest transcripts in both ypd and gal\n",
    "#Note=Difference between CDS and maximum of longest transcripts\n",
    "\n",
    "\n",
    "\n",
    "#Concatenate sgd GFF with longest transcript gff from gal and ypd\n",
    "\n",
    "#Assign transcripts as transcripts, children to the appropriate parent gene\n",
    "\n",
    "#Assign ID for long transcript as follows: \n",
    "#ID=genename_trans.long.cond.N\n",
    "#cond is gal or ypd, and number is taken from the original file eg id001\n",
    "#Note=gal count X\n",
    "\n",
    "#obtain coordinates of extent of both ypd and gal transcrips for a particular gene\n",
    "\n",
    "#make a new transcript: \n",
    "#source column: heineike_2020\n",
    "#in description column: \n",
    "#ID=genename_trans.long.max\n",
    "\n",
    "\n",
    "\n",
    "#Use that to extend the coordinates of genes\n",
    "\n",
    "\n",
    "#Subtract existing coordinates of the gene to build \n",
    "\n",
    "#source: heineike_2020\n",
    "#three_prime_utr\n",
    "#ID=genename_3pUTR.long.max or genename_5pUTR.long.max\n",
    "#child of transcript\n",
    "\n",
    "#output this file as an intermediate step to send to SGD/etc if they don't want the combined feature. \n",
    "\n",
    "#Make a transcript_region that consists of three_prime_utr and CDS in order to \n",
    "#count reads falling in the three prime region.  \n",
    "\n",
    "#source: heineike_2020\n",
    "#transcript_region\n",
    "#ID=genename_CDS.3pUTR\n",
    "#child of gene - if Parent field is filled, that will work for htseq-count\n",
    "\n",
    "#First ensure that no other features in the file consist of transcript regions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build dictionary keying gene to the coordinate of the next CDS on the same strand to define a maximum intergenic region\n",
    "unique_ids_table = pd.read_table(genome_assy_dir+os.sep + sc_ref_base + '_unique_ids.gff', header=None, skiprows=1)\n",
    "chrms = list(set(unique_ids_table[0]))\n",
    "strands = ['+','-']\n",
    "\n",
    "chrm_table = unique_ids_table[unique_ids_table[2]=='chromosome']\n",
    "chrm_len_dict = dict(zip(chrm_table[0],chrm_table[4]))\n",
    "\n",
    "unique_ids_table_genes = unique_ids_table[unique_ids_table[2]=='gene'].copy()\n",
    "# for chrm in chrms:\n",
    "#     for strand in strands:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "genenames = []\n",
    "for ind, row in unique_ids_table_genes.iterrows():\n",
    "    genename = row[8].split(';')[0].split('=')[1]\n",
    "    genenames.append(genename)\n",
    "unique_ids_table_genes['genenames']=genenames\n",
    "unique_ids_table_genes.set_index('genenames', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230218"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrm_len_dict[chrm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>3prime_limit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genenames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YEL077C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>264</td>\n",
       "      <td>4097</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YEL077C;Name=YEL077C;Alias=Y' element ATP-d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEL076C-A</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>4185</td>\n",
       "      <td>5114</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YEL076C-A;Name=YEL076C-A;Ontology_term=GO:0...</td>\n",
       "      <td>4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEL076C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>4464</td>\n",
       "      <td>5114</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YEL076C;Name=YEL076C;Ontology_term=GO:00036...</td>\n",
       "      <td>5114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEL075C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>5345</td>\n",
       "      <td>5713</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YEL075C;Name=YEL075C;Ontology_term=GO:00036...</td>\n",
       "      <td>5114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEL073C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>7230</td>\n",
       "      <td>7553</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YEL073C;Name=YEL073C;Ontology_term=GO:00036...</td>\n",
       "      <td>5713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YER183C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>553334</td>\n",
       "      <td>553969</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YER183C;Name=YER183C;gene=FAU1;Alias=FAU1,5...</td>\n",
       "      <td>551122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YER184C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>556296</td>\n",
       "      <td>558680</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YER184C;Name=YER184C;gene=TOG1;Alias=TOG1;O...</td>\n",
       "      <td>553969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YER186C</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>561705</td>\n",
       "      <td>562625</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YER186C;Name=YER186C;Ontology_term=GO:00036...</td>\n",
       "      <td>558680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YER188C-A</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>569608</td>\n",
       "      <td>569907</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YER188C-A;Name=YER188C-A;Ontology_term=GO:0...</td>\n",
       "      <td>562625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YER190C-B</th>\n",
       "      <td>V</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>575680</td>\n",
       "      <td>576162</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YER190C-B;Name=YER190C-B;Ontology_term=GO:0...</td>\n",
       "      <td>569907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1     2       3       4  5  6  7  \\\n",
       "genenames                                          \n",
       "YEL077C    V  SGD  gene     264    4097  .  -  .   \n",
       "YEL076C-A  V  SGD  gene    4185    5114  .  -  .   \n",
       "YEL076C    V  SGD  gene    4464    5114  .  -  .   \n",
       "YEL075C    V  SGD  gene    5345    5713  .  -  .   \n",
       "YEL073C    V  SGD  gene    7230    7553  .  -  .   \n",
       "...       ..  ...   ...     ...     ... .. .. ..   \n",
       "YER183C    V  SGD  gene  553334  553969  .  -  .   \n",
       "YER184C    V  SGD  gene  556296  558680  .  -  .   \n",
       "YER186C    V  SGD  gene  561705  562625  .  -  .   \n",
       "YER188C-A  V  SGD  gene  569608  569907  .  -  .   \n",
       "YER190C-B  V  SGD  gene  575680  576162  .  -  .   \n",
       "\n",
       "                                                           8  3prime_limit  \n",
       "genenames                                                                   \n",
       "YEL077C    ID=YEL077C;Name=YEL077C;Alias=Y' element ATP-d...             0  \n",
       "YEL076C-A  ID=YEL076C-A;Name=YEL076C-A;Ontology_term=GO:0...          4097  \n",
       "YEL076C    ID=YEL076C;Name=YEL076C;Ontology_term=GO:00036...          5114  \n",
       "YEL075C    ID=YEL075C;Name=YEL075C;Ontology_term=GO:00036...          5114  \n",
       "YEL073C    ID=YEL073C;Name=YEL073C;Ontology_term=GO:00036...          5713  \n",
       "...                                                      ...           ...  \n",
       "YER183C    ID=YER183C;Name=YER183C;gene=FAU1;Alias=FAU1,5...        551122  \n",
       "YER184C    ID=YER184C;Name=YER184C;gene=TOG1;Alias=TOG1;O...        553969  \n",
       "YER186C    ID=YER186C;Name=YER186C;Ontology_term=GO:00036...        558680  \n",
       "YER188C-A  ID=YER188C-A;Name=YER188C-A;Ontology_term=GO:0...        562625  \n",
       "YER190C-B  ID=YER190C-B;Name=YER190C-B;Ontology_term=GO:0...        569907  \n",
       "\n",
       "[134 rows x 10 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Put it into a dictionary\n",
    "\n",
    "chrm = 'V'\n",
    "strand = '-'\n",
    "genes_chrm_strand = unique_ids_table_genes[(unique_ids_table_genes[0]==chrm) & (unique_ids_table_genes[6]==strand)].copy()\n",
    "\n",
    "genes_chrm_strand.sort_values(by=[3],axis=0, inplace=True)\n",
    "\n",
    "\n",
    "if strand=='+':\n",
    "    #if it is the plus strand, associate each gene with the start of the next gene\n",
    "    #genes_chrm_strand['3prime_limit'] = list(genes_chrm_strand[3].values[1:]) + [chrm_len_dict[chrm]]\n",
    "    next_starts = []\n",
    "    ind_max = len(genes_chrm_strand)-1\n",
    "    for ind, (gene,row) in enumerate(genes_chrm_strand.iterrows()):\n",
    "        end = int(row[4])\n",
    "        next_start = 'Unassigned'\n",
    "        ind_try=ind\n",
    "        #The next start needs to be greater than the end of the current gene\n",
    "        while next_start=='Unassigned':\n",
    "            ind_try = ind_try + 1\n",
    "            if ind_try<ind_max:\n",
    "                next_start_try = int(genes_chrm_strand.iloc[ind_try,3])\n",
    "                if next_start_try>end:\n",
    "                    next_start=next_start_try-1\n",
    "            else:\n",
    "                next_start=chrm_len_dict[chrm]\n",
    "        next_starts.append(next_start)\n",
    "    genes_chrm_strand['3prime_limit'] = next_starts\n",
    "    \n",
    "    \n",
    "elif strand=='-':\n",
    "    #If it is the minus strand, associate each gene with the end of the previous gene\n",
    "    #genes_chrm_strand['3prime_limit'] = [0] + list(genes_chrm_strand[4].values[:-1]) \n",
    "    previous_ends = []\n",
    "    for ind, (gene,row) in enumerate(genes_chrm_strand.iterrows()):\n",
    "        start = int(row[3])\n",
    "        previous_end = 'Unassigned'\n",
    "        ind_try=ind\n",
    "        #The next start needs to be greater than the end of the current gene\n",
    "        while previous_end=='Unassigned':\n",
    "            ind_try = ind_try - 1\n",
    "            if ind_try<0:\n",
    "                previous_end = 0\n",
    "            else: \n",
    "                previous_end_try = int(genes_chrm_strand.iloc[ind_try,4])\n",
    "                if previous_end_try<start:\n",
    "                    previous_end=previous_end_try+1\n",
    "        previous_ends.append(previous_end)\n",
    "    genes_chrm_strand['3prime_limit'] = previous_ends\n",
    "\n",
    "genes_chrm_strand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through all genes, identify complete overlaps, and partial overlaps\n",
    "#\n",
    "#Make bed file of just genes\n",
    "#Need to convert start to 0 index, but end stays the same.\n",
    "\n",
    "#sort out the rows by chromosome and then by start value\n",
    "unique_ids_table_genes.sort_values(by=[0,3],axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Bedfile consisting only of genes\n",
    "bed_fname = genome_assy_dir+os.sep + sc_ref_base + '_unique_ids_genes.bed'\n",
    "with open(bed_fname,'w') as bed_file:\n",
    "    for ind,row in unique_ids_table_genes.iterrows():\n",
    "        genename = row[8].split(';')[0].split('=')[1]\n",
    "        bed_file.write(\"{}\\t{}\\t{}\\t{}\\t.\\t{}\\n\".format(row[0],str(int(row[3])-1),row[4],genename,row[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_bed = pybedtools.BedTool(bed_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = genes_bed.merge(S='+', c=[1,4,2,3], o=['count', 'collapse','collapse', 'collapse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', '2479', '2707', '+', '1', 'YAL067W-A', '2479', '2707']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b[0]\n",
    "c.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YCL042W,YCL040W\n",
      "50583,50837\n",
      "50943,52340\n",
      "YCR040W,YCR041W\n",
      "200441,200910\n",
      "200969,201243\n",
      "Q0050,Q0055,Q0060,Q0065,Q0070,Q0045,Q0075\n",
      "13817,13817,13817,13817,13817,13817,24155\n",
      "16322,18830,19996,21935,23167,26701,25255\n",
      "Q0110,Q0115,Q0120,Q0105\n",
      "36539,36539,36539,36539\n",
      "38579,40265,42251,43647\n",
      "Q0250,Q0255\n",
      "73757,74494\n",
      "74513,75984\n",
      "YER189W,YER190W\n",
      "571154,571479\n",
      "571523,576525\n",
      "YJR078W,YJR079W\n",
      "578859,580204\n",
      "580221,581239\n",
      "YJR146W,YJR147W\n",
      "703884,704195\n",
      "704238,705272\n",
      "YLR464W,YLR466W\n",
      "1066571,1067086\n",
      "1067501,1071235\n",
      "YOR104W,YOR105W\n",
      "517641,518194\n",
      "518490,518521\n",
      "YPR202W,YPR203W\n",
      "943031,943879\n",
      "943896,944188\n"
     ]
    }
   ],
   "source": [
    "for row in b: \n",
    "    n_overlap = int(row.fields[4])\n",
    "    if n_overlap > 1:\n",
    "        print(row.fields[5])\n",
    "        print(row.fields[6])\n",
    "        print(row.fields[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>2480</td>\n",
       "      <td>2707</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL067W-A;Name=YAL067W-A;Ontology_term=GO:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>12046</td>\n",
       "      <td>12426</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL064W-B;Name=YAL064W-B;Ontology_term=GO:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>21566</td>\n",
       "      <td>21850</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL064W;Name=YAL064W;Ontology_term=GO:00036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>31567</td>\n",
       "      <td>32940</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL062W;Name=YAL062W;gene=GDH3;Alias=GDH3,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>33448</td>\n",
       "      <td>34701</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL061W;Name=YAL061W;gene=BDH2;Alias=BDH2,p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>35155</td>\n",
       "      <td>36303</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL060W;Name=YAL060W;gene=BDH1;Alias=BDH1,(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>36509</td>\n",
       "      <td>37147</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL059W;Name=YAL059W;gene=ECM1;Alias=ECM1;O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>37464</td>\n",
       "      <td>38972</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL058W;Name=YAL058W;gene=CNE1;Alias=CNE1,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>39259</td>\n",
       "      <td>41901</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL056W;Name=YAL056W;gene=GPB2;Alias=GPB2,K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>42177</td>\n",
       "      <td>42719</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL055W;Name=YAL055W;gene=PEX22;Alias=PEX22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>45899</td>\n",
       "      <td>48250</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL053W;Name=YAL053W;gene=FLC2;Alias=FLC2,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>48564</td>\n",
       "      <td>51707</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL051W;Name=YAL051W;gene=OAF1;Alias=OAF1,Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>57518</td>\n",
       "      <td>57850</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL044W-A;Name=YAL044W-A;Ontology_term=GO:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>61316</td>\n",
       "      <td>62563</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL042W;Name=YAL042W;gene=ERV46;Alias=ERV46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>62840</td>\n",
       "      <td>65404</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL041W;Name=YAL041W;gene=CDC24;Alias=CDC24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>71786</td>\n",
       "      <td>73288</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL038W;Name=YAL038W;gene=CDC19;Alias=CDC19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>74020</td>\n",
       "      <td>74823</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL037W;Name=YAL037W;Ontology_term=GO:00036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>76427</td>\n",
       "      <td>79435</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL035W;Name=YAL035W;gene=FUN12;Alias=FUN12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>79718</td>\n",
       "      <td>80587</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL034W-A;Name=YAL034W-A;gene=MTW1;Alias=MT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>82706</td>\n",
       "      <td>83227</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL033W;Name=YAL033W;gene=POP5;Alias=POP5,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>87286</td>\n",
       "      <td>87752</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL030W;Name=YAL030W;gene=SNC1;Alias=SNC1,S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>92900</td>\n",
       "      <td>94486</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL028W;Name=YAL028W;gene=FRT2;Alias=FRT2,H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>94687</td>\n",
       "      <td>95472</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL027W;Name=YAL027W;gene=SAW1;Alias=SAW1,D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>114919</td>\n",
       "      <td>118314</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL019W;Name=YAL019W;gene=FUN30;Alias=FUN30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>120225</td>\n",
       "      <td>124295</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL017W;Name=YAL017W;gene=PSK1;Alias=PSK1,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>124879</td>\n",
       "      <td>126786</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL016W;Name=YAL016W;gene=TPD3;Alias=TPD3,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>129270</td>\n",
       "      <td>130487</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL013W;Name=YAL013W;gene=DEP1;Alias=DEP1,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>130799</td>\n",
       "      <td>131983</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL012W;Name=YAL012W;gene=CYS3;Alias=CYS3,C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>132199</td>\n",
       "      <td>134076</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL011W;Name=YAL011W;gene=SWC3;Alias=SWC3,S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>135854</td>\n",
       "      <td>136633</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL009W;Name=YAL009W;gene=SPO7;Alias=SPO7,N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>136914</td>\n",
       "      <td>137510</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL008W;Name=YAL008W;gene=FUN14;Alias=FUN14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>142174</td>\n",
       "      <td>143160</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL003W;Name=YAL003W;gene=EFB1;Alias=EFB1,E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>143707</td>\n",
       "      <td>147531</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAL002W;Name=YAL002W;gene=VPS8;Alias=VPS8,C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>152257</td>\n",
       "      <td>153876</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR002W;Name=YAR002W;gene=NUP60;Alias=NUP60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>155005</td>\n",
       "      <td>156285</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR003W;Name=YAR003W;gene=SWD1;Alias=SWD1,C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>158966</td>\n",
       "      <td>159793</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR008W;Name=YAR008W;gene=SEN34;Alias=SEN34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>169375</td>\n",
       "      <td>170295</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR015W;Name=YAR015W;gene=ADE1;Alias=ADE1,p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>183770</td>\n",
       "      <td>184477</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR027W;Name=YAR027W;gene=UIP3;Alias=UIP3,D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>184892</td>\n",
       "      <td>185596</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR028W;Name=YAR028W;Alias=DUP240 family pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>186321</td>\n",
       "      <td>186545</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR029W;Name=YAR029W;Alias=DUP240 family pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>186836</td>\n",
       "      <td>187732</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR031W;Name=YAR031W;gene=PRM9;Alias=PRM9,p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>188107</td>\n",
       "      <td>188811</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR033W;Name=YAR033W;gene=MST28;Alias=MST28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>190193</td>\n",
       "      <td>192256</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR035W;Name=YAR035W;gene=YAT1;Alias=YAT1,c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>192619</td>\n",
       "      <td>196185</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR042W;Name=YAR042W;gene=SWH1;Alias=SWH1,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>203403</td>\n",
       "      <td>208016</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR050W;Name=YAR050W;gene=FLO1;Alias=FLO1,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>220198</td>\n",
       "      <td>220497</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR064W;Name=YAR064W;Ontology_term=GO:00036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>221049</td>\n",
       "      <td>221660</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR066W;Name=YAR066W;Ontology_term=GO:00036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>222406</td>\n",
       "      <td>222891</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR068W;Name=YAR068W;Ontology_term=GO:00036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>I</td>\n",
       "      <td>SGD</td>\n",
       "      <td>gene</td>\n",
       "      <td>225460</td>\n",
       "      <td>226863</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=YAR071W;Name=YAR071W;gene=PHO11;Alias=PHO11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2       3       4  5  6  7  \\\n",
       "10   I  SGD  gene    2480    2707  .  +  .   \n",
       "20   I  SGD  gene   12046   12426  .  +  .   \n",
       "26   I  SGD  gene   21566   21850  .  +  .   \n",
       "39   I  SGD  gene   31567   32940  .  +  .   \n",
       "42   I  SGD  gene   33448   34701  .  +  .   \n",
       "45   I  SGD  gene   35155   36303  .  +  .   \n",
       "48   I  SGD  gene   36509   37147  .  +  .   \n",
       "51   I  SGD  gene   37464   38972  .  +  .   \n",
       "54   I  SGD  gene   39259   41901  .  +  .   \n",
       "58   I  SGD  gene   42177   42719  .  +  .   \n",
       "64   I  SGD  gene   45899   48250  .  +  .   \n",
       "67   I  SGD  gene   48564   51707  .  +  .   \n",
       "82   I  SGD  gene   57518   57850  .  +  .   \n",
       "91   I  SGD  gene   61316   62563  .  +  .   \n",
       "94   I  SGD  gene   62840   65404  .  +  .   \n",
       "106  I  SGD  gene   71786   73288  .  +  .   \n",
       "112  I  SGD  gene   74020   74823  .  +  .   \n",
       "118  I  SGD  gene   76427   79435  .  +  .   \n",
       "121  I  SGD  gene   79718   80587  .  +  .   \n",
       "127  I  SGD  gene   82706   83227  .  +  .   \n",
       "136  I  SGD  gene   87286   87752  .  +  .   \n",
       "144  I  SGD  gene   92900   94486  .  +  .   \n",
       "147  I  SGD  gene   94687   95472  .  +  .   \n",
       "174  I  SGD  gene  114919  118314  .  +  .   \n",
       "180  I  SGD  gene  120225  124295  .  +  .   \n",
       "185  I  SGD  gene  124879  126786  .  +  .   \n",
       "194  I  SGD  gene  129270  130487  .  +  .   \n",
       "197  I  SGD  gene  130799  131983  .  +  .   \n",
       "201  I  SGD  gene  132199  134076  .  +  .   \n",
       "207  I  SGD  gene  135854  136633  .  +  .   \n",
       "210  I  SGD  gene  136914  137510  .  +  .   \n",
       "224  I  SGD  gene  142174  143160  .  +  .   \n",
       "231  I  SGD  gene  143707  147531  .  +  .   \n",
       "244  I  SGD  gene  152257  153876  .  +  .   \n",
       "250  I  SGD  gene  155005  156285  .  +  .   \n",
       "256  I  SGD  gene  158966  159793  .  +  .   \n",
       "275  I  SGD  gene  169375  170295  .  +  .   \n",
       "301  I  SGD  gene  183770  184477  .  +  .   \n",
       "304  I  SGD  gene  184892  185596  .  +  .   \n",
       "307  I  SGD  gene  186321  186545  .  +  .   \n",
       "310  I  SGD  gene  186836  187732  .  +  .   \n",
       "313  I  SGD  gene  188107  188811  .  +  .   \n",
       "317  I  SGD  gene  190193  192256  .  +  .   \n",
       "323  I  SGD  gene  192619  196185  .  +  .   \n",
       "326  I  SGD  gene  203403  208016  .  +  .   \n",
       "333  I  SGD  gene  220198  220497  .  +  .   \n",
       "336  I  SGD  gene  221049  221660  .  +  .   \n",
       "339  I  SGD  gene  222406  222891  .  +  .   \n",
       "343  I  SGD  gene  225460  226863  .  +  .   \n",
       "\n",
       "                                                     8  \n",
       "10   ID=YAL067W-A;Name=YAL067W-A;Ontology_term=GO:0...  \n",
       "20   ID=YAL064W-B;Name=YAL064W-B;Ontology_term=GO:0...  \n",
       "26   ID=YAL064W;Name=YAL064W;Ontology_term=GO:00036...  \n",
       "39   ID=YAL062W;Name=YAL062W;gene=GDH3;Alias=GDH3,F...  \n",
       "42   ID=YAL061W;Name=YAL061W;gene=BDH2;Alias=BDH2,p...  \n",
       "45   ID=YAL060W;Name=YAL060W;gene=BDH1;Alias=BDH1,(...  \n",
       "48   ID=YAL059W;Name=YAL059W;gene=ECM1;Alias=ECM1;O...  \n",
       "51   ID=YAL058W;Name=YAL058W;gene=CNE1;Alias=CNE1,F...  \n",
       "54   ID=YAL056W;Name=YAL056W;gene=GPB2;Alias=GPB2,K...  \n",
       "58   ID=YAL055W;Name=YAL055W;gene=PEX22;Alias=PEX22...  \n",
       "64   ID=YAL053W;Name=YAL053W;gene=FLC2;Alias=FLC2,F...  \n",
       "67   ID=YAL051W;Name=YAL051W;gene=OAF1;Alias=OAF1,Y...  \n",
       "82   ID=YAL044W-A;Name=YAL044W-A;Ontology_term=GO:0...  \n",
       "91   ID=YAL042W;Name=YAL042W;gene=ERV46;Alias=ERV46...  \n",
       "94   ID=YAL041W;Name=YAL041W;gene=CDC24;Alias=CDC24...  \n",
       "106  ID=YAL038W;Name=YAL038W;gene=CDC19;Alias=CDC19...  \n",
       "112  ID=YAL037W;Name=YAL037W;Ontology_term=GO:00036...  \n",
       "118  ID=YAL035W;Name=YAL035W;gene=FUN12;Alias=FUN12...  \n",
       "121  ID=YAL034W-A;Name=YAL034W-A;gene=MTW1;Alias=MT...  \n",
       "127  ID=YAL033W;Name=YAL033W;gene=POP5;Alias=POP5,F...  \n",
       "136  ID=YAL030W;Name=YAL030W;gene=SNC1;Alias=SNC1,S...  \n",
       "144  ID=YAL028W;Name=YAL028W;gene=FRT2;Alias=FRT2,H...  \n",
       "147  ID=YAL027W;Name=YAL027W;gene=SAW1;Alias=SAW1,D...  \n",
       "174  ID=YAL019W;Name=YAL019W;gene=FUN30;Alias=FUN30...  \n",
       "180  ID=YAL017W;Name=YAL017W;gene=PSK1;Alias=PSK1,F...  \n",
       "185  ID=YAL016W;Name=YAL016W;gene=TPD3;Alias=TPD3,F...  \n",
       "194  ID=YAL013W;Name=YAL013W;gene=DEP1;Alias=DEP1,F...  \n",
       "197  ID=YAL012W;Name=YAL012W;gene=CYS3;Alias=CYS3,C...  \n",
       "201  ID=YAL011W;Name=YAL011W;gene=SWC3;Alias=SWC3,S...  \n",
       "207  ID=YAL009W;Name=YAL009W;gene=SPO7;Alias=SPO7,N...  \n",
       "210  ID=YAL008W;Name=YAL008W;gene=FUN14;Alias=FUN14...  \n",
       "224  ID=YAL003W;Name=YAL003W;gene=EFB1;Alias=EFB1,E...  \n",
       "231  ID=YAL002W;Name=YAL002W;gene=VPS8;Alias=VPS8,C...  \n",
       "244  ID=YAR002W;Name=YAR002W;gene=NUP60;Alias=NUP60...  \n",
       "250  ID=YAR003W;Name=YAR003W;gene=SWD1;Alias=SWD1,C...  \n",
       "256  ID=YAR008W;Name=YAR008W;gene=SEN34;Alias=SEN34...  \n",
       "275  ID=YAR015W;Name=YAR015W;gene=ADE1;Alias=ADE1,p...  \n",
       "301  ID=YAR027W;Name=YAR027W;gene=UIP3;Alias=UIP3,D...  \n",
       "304  ID=YAR028W;Name=YAR028W;Alias=DUP240 family pr...  \n",
       "307  ID=YAR029W;Name=YAR029W;Alias=DUP240 family pr...  \n",
       "310  ID=YAR031W;Name=YAR031W;gene=PRM9;Alias=PRM9,p...  \n",
       "313  ID=YAR033W;Name=YAR033W;gene=MST28;Alias=MST28...  \n",
       "317  ID=YAR035W;Name=YAR035W;gene=YAT1;Alias=YAT1,c...  \n",
       "323  ID=YAR042W;Name=YAR042W;gene=SWH1;Alias=SWH1,O...  \n",
       "326  ID=YAR050W;Name=YAR050W;gene=FLO1;Alias=FLO1,F...  \n",
       "333  ID=YAR064W;Name=YAR064W;Ontology_term=GO:00036...  \n",
       "336  ID=YAR066W;Name=YAR066W;Ontology_term=GO:00036...  \n",
       "339  ID=YAR068W;Name=YAR068W;Ontology_term=GO:00036...  \n",
       "343  ID=YAR071W;Name=YAR071W;gene=PHO11;Alias=PHO11...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unique_ids_table[(unique_ids_table[0]==chrm) & (unique_ids_table[2]=='gene') & (unique_ids_table[6]==strand)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges two gtf files and outputs to new file\n",
    "\n",
    "merged_fn = genome_assy_dir+os.sep + sc_ref_base + '_tifs.gff'\n",
    "duborf_fn = genome_assy_dir+os.sep + 'dubious_orfs_with_tifs.gff'\n",
    "sgd_tif_max_fn = {}\n",
    "for cond in ['ypd','gal']:\n",
    "    sgd_tif_max_fn[cond] = genome_assy_dir + os.sep + 'SGD_pelechano_reanalysis' +os.sep +\"longest_full-ORF_transcripts_\" + cond + \".gff3\"\n",
    "\n",
    "with open(merged_fn, 'w') as outfile:\n",
    "    with open(duborf_fn, 'w') as duborffile: \n",
    "        with open(genome_assy_dir+os.sep + sc_ref_base + '_unique_ids.gff') as sc_ref_file:\n",
    "            for line in sc_ref_file:\n",
    "                outfile.write(line)\n",
    "            #         #keep first line: \n",
    "    #         outfile.write(sc_ref_file.readline())\n",
    "    #         #drop header lines\n",
    "    #         for jj in range(0,17):\n",
    "    #             #print(sc_ref_file.readline())\n",
    "    #             sc_ref_file.readline()\n",
    "    #         for line in sc_ref_file: \n",
    "    #             if line[0:3]=='chr':\n",
    "    #                 outfile.write(line)\n",
    "    #             else: \n",
    "    #                 break\n",
    "        #add transcript data for each condition\n",
    "        for cond in ['ypd','gal']:\n",
    "            with open(sgd_tif_max_fn[cond]) as transcript_file:    \n",
    "                #drop header lines\n",
    "                for  jj in range(0,3):\n",
    "                    line = transcript_file.readline()\n",
    "                    #print(line)\n",
    "                for old_line in transcript_file:\n",
    "                    #old_line = \"chrI\tSGD\tprimary_transcript\t143550\t147630\t.\t+\t.\tgal=1;ID=YAL002W_id001\"\n",
    "\n",
    "                    linesp = old_line.split('\\t')\n",
    "\n",
    "                    #rename chromosome\n",
    "                    linesp[0] = chromosome_rename_dict[linesp[0]]\n",
    "\n",
    "                    #reclassify source\n",
    "                    linesp[1] = 'SGD_Pelechano_2013'\n",
    "\n",
    "                    #reclassify type as transcript\n",
    "                    linesp[2] = 'transcript'\n",
    "\n",
    "\n",
    "\n",
    "                    #ID= genename_trans.long.cond.sgd_id;\n",
    "                    #Parent=genename;\n",
    "                    #Note=cond count X\n",
    "                    atts = linesp[8]\n",
    "                    atts_split = atts.split(';')\n",
    "                    cond, count = atts_split[0].split('=')\n",
    "                    genename, sgd_id = atts_split[1].split('=')[1].split('_')\n",
    "                    sgd_id = sgd_id.strip('\\n')\n",
    "                    linesp[8] = 'ID={}.long.{}.{};Parent={};condition={};count={}\\n'.format(genename,cond,sgd_id,genename,cond,count)\n",
    "                    new_line = '\\t'.join(linesp)\n",
    "                    if genename in dub_orf_list:\n",
    "                        duborffile.write(new_line)\n",
    "                    else: \n",
    "                        outfile.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the merged.gff as a database\n",
    "\n",
    "#merged_db.conn.close()    #when troubleshooting you may need to close the database before remaking it. \n",
    "\n",
    "\n",
    "merged_db = gffutils.create_db(merged_fn, dbfn=genome_assy_dir + os.sep + sc_ref_base + '_tifs.db', \n",
    "                               id_spec=('ID', 'Name'), \n",
    "                               merge_strategy='error', \n",
    "                               force=True,  #makes new database\n",
    "                               #keep_order=True, see no reason to keep this\n",
    "                               force_gff = True)\n",
    "#,\n",
    "                               #force_dialect_check = True)\n",
    "                               #sort_attribute_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary that lists the 5' end of the next ORF on the same strand\n",
    "all_chrms = []\n",
    "all_chrms_query = merged_db.execute('SELECT DISTINCT seqid FROM features').fetchall()\n",
    "for chrm in all_chrms_query:\n",
    "    all_chrms.append(chrm['seqid'])\n",
    "\n",
    "for chrm in all_chrms: \n",
    "    for strand in ['+','-']:\n",
    "        c = strand\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = merged_db.execute(\"SELECT id, start FROM features WHERE seqid='\"+ chrm + \"' AND strand='\" + strand +\"' AND featuretype='gene'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =a.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YPL283C'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrms = []\n",
    "for item in b:\n",
    "    c = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 YDL020C\n",
      "2000 YER039C\n",
      "3000 YHR028C\n",
      "4000 YLL046C\n",
      "5000 YMR276W\n",
      "6000 YOR313C\n",
      "Updating Database with Max transcripts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gffutils.create._GFFDBCreator at 0x7f539b978748>"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iterate through genes, make big transcript features\n",
    "\n",
    "#make a new transcript: \n",
    "#source column: heineike_2020\n",
    "#start and stop at the min and max of the longest transcripts for both YPD and gal.  \n",
    "#ID=genename_trans.long.max\n",
    "#remove Note from attributes\n",
    "\n",
    "max_transcripts = []\n",
    "N =1\n",
    "for feature in merged_db.features_of_type('gene'):\n",
    "    genename = feature.id\n",
    "    N = N+1\n",
    "    if np.mod(N,1000)==0:\n",
    "        print(str(N) + ' ' + genename)\n",
    "    transcript_dict = {}\n",
    "    transcripts_present=False\n",
    "    need_copy_for_max_transcript = True\n",
    "    for gene_child in merged_db.children(genename): \n",
    "        if gene_child.featuretype=='transcript':\n",
    "            transcripts_present=True\n",
    "            if need_copy_for_max_transcript:\n",
    "                max_transcript_base = gene_child\n",
    "                need_copy_for_max_transcript=False\n",
    "            assert gene_child.source == 'SGD_Pelechano_2013', 'transcript not from Pelechano 2013'\n",
    "            #dictionary is keyed on condition and has tuple representing start and end coordinates of transcript\n",
    "            genename_child, filt, cond, sgd_id = gene_child.id.split('.')\n",
    "            assert genename_child==genename, 'Child genename not equal to genename'\n",
    "            if filt=='long':\n",
    "                transcript_dict[cond] = (gene_child.start, gene_child.end)\n",
    "\n",
    "\n",
    "    if transcripts_present: \n",
    "        #Define new coords as max extend of coords in gal and YPD\n",
    "        starts = [coords[0] for coords in transcript_dict.values()]\n",
    "        ends = [coords[1] for coords in transcript_dict.values()]\n",
    "        new_coords = (min(starts),max(ends))\n",
    "        \n",
    "        #Had to use Feature class directly because I wanted to remove the Note attribute. \n",
    "        max_transcript = gffutils.Feature(seqid=max_transcript_base.seqid, \n",
    "                                    source = 'Heineike_2020',\n",
    "                                    featuretype= max_transcript_base.featuretype,\n",
    "                                    start = new_coords[0],\n",
    "                                    end = new_coords[1],\n",
    "                                    strand = max_transcript_base.strand,\n",
    "                                    frame = max_transcript_base.frame, \n",
    "                                    attributes = {'ID': [genename + '.long.max'], \n",
    "                                                  'Parent': [genename]}\n",
    "                                   )  \n",
    "        max_transcripts.append(max_transcript)\n",
    "\n",
    "print('Updating Database with Max transcripts')\n",
    "merged_db.update(max_transcripts, merge_strategy='error', id_spec='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print to file\n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_max_transcripts.gff', 'w') as outfile:\n",
    "    outfile.write('##gff-version 3\\n')\n",
    "    for feature in merged_db.all_features(order_by = ('seqid','start','featuretype')):\n",
    "         print(feature,file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 YDL019C\n",
      "2000 YER039C-A\n",
      "3000 YHR028W-A\n",
      "4000 YLL045C\n",
      "5000 YMR277W\n",
      "6000 YOR314W\n"
     ]
    }
   ],
   "source": [
    "#Cycles through all genes, makes 3'UTR and 5'UTR from max of difference between CDS\n",
    "\n",
    "#source: heineike_2020\n",
    "#CDS_3pUTR\n",
    "#ID=genename_CDS_3pUTR.long\n",
    "#child of gene - if Parent field is filled, that will work for htseq-count\n",
    "\n",
    "features_to_add = []\n",
    "N=0\n",
    "for feature in merged_db.features_of_type('gene'):\n",
    "    genename = feature.id\n",
    "    seqid = feature.seqid\n",
    "    strand = feature.strand\n",
    "    \n",
    "    N = N+1\n",
    "    if np.mod(N,1000)==0:\n",
    "        print(str(N) + ' ' + genename)\n",
    "\n",
    "    gene_data = {'CDS': []}\n",
    "    for child in merged_db.children(genename):\n",
    "        if child.featuretype=='CDS':\n",
    "            gene_data['CDS'].append(child)\n",
    "        elif child.featuretype=='transcript' and child.id.split('.')[2]=='max':\n",
    "            gene_data['max']=child\n",
    "            \n",
    "    if gene_data['CDS']==[]:\n",
    "        raise ValueError('No CDS for ' + genename)\n",
    "\n",
    "    CDS_low = min([cds.start for cds in gene_data['CDS']])\n",
    "    CDS_high = max([cds.end for cds in gene_data['CDS']])\n",
    "\n",
    "    if 'max' in gene_data.keys():\n",
    "        if strand=='-': \n",
    "            utr3p_coords = (gene_data['max'].start,CDS_low)\n",
    "            utr5p_coords = (CDS_high, gene_data['max'].end)\n",
    "        elif strand=='+':\n",
    "            utr3p_coords = (CDS_high, gene_data['max'].end)               \n",
    "            utr5p_coords = (gene_data['max'].start,CDS_low)\n",
    "\n",
    "        #Make 3'UTR features \n",
    "        utr3p = gffutils.Feature(seqid=seqid, \n",
    "                                 source = 'Heineike_2020',\n",
    "                                 featuretype = 'three_prime_utr',\n",
    "                                 start = utr3p_coords[0],\n",
    "                                 end = utr3p_coords[1],\n",
    "                                 strand = strand,\n",
    "                                 frame = '.', \n",
    "                                 attributes = {'ID': [genename + '_3pUTR.long.max'], \n",
    "                                               'Parent': [genename], \n",
    "                                               'Length': ['{}'.format(utr3p_coords[1]-utr3p_coords[0])]  \n",
    "                                              }\n",
    "                                       )\n",
    "        features_to_add.append(utr3p)\n",
    "        \n",
    "        #Make 5'UTR features \n",
    "        utr5p = gffutils.Feature(seqid=seqid, \n",
    "                                 source = 'Heineike_2020',\n",
    "                                 featuretype = 'five_prime_utr',\n",
    "                                 start = utr5p_coords[0],\n",
    "                                 end = utr5p_coords[1],\n",
    "                                 strand = strand,\n",
    "                                 frame = '.', \n",
    "                                 attributes = {'ID': [genename + '_5pUTR.long.max'], \n",
    "                                               'Parent': [genename], \n",
    "                                               'length': ['{}'.format(utr5p_coords[1]-utr5p_coords[0])]  \n",
    "                                              }\n",
    "                                       )\n",
    "\n",
    "        features_to_add.append(utr5p)\n",
    "\n",
    "\n",
    "    #Add combined CDS/3p_UTR\n",
    "    utr_flag = 'False'\n",
    "    if 'max' in gene_data.keys():\n",
    "        #If this is true then there will be a 3pUTR\n",
    "        utr_flag ='True'\n",
    "        if strand=='-':\n",
    "            coords = (utr3p_coords[0], CDS_high)\n",
    "        elif strand=='+':\n",
    "            coords = (CDS_low, utr3p_coords[1])\n",
    "    else: \n",
    "        coords = (CDS_low, CDS_high)\n",
    "\n",
    "    cds_utr3p = gffutils.Feature(seqid=seqid, \n",
    "                             source = 'Heineike_2020',\n",
    "                             featuretype = 'CDS_3pUTR',\n",
    "                             start = coords[0],\n",
    "                             end = coords[1],\n",
    "                             strand = strand,\n",
    "                             frame = '.', \n",
    "                             attributes = {'ID': [genename + '_CDS_3pUTR.long'], \n",
    "                                           'Parent': [genename], \n",
    "                                           'utr': [utr_flag]  \n",
    "                                          }\n",
    "                                   )\n",
    "    \n",
    "    features_to_add.append(cds_utr3p)  \n",
    "\n",
    "# print('Updating Database')\n",
    "# merged_db.update(max_transcripts, merge_strategy='error', id_spec='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Database with UTRs and combined CDS/UTR feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gffutils.create._GFFDBCreator at 0x7f539bd57240>"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Updating Database with UTRs and combined CDS/UTR feature')\n",
    "merged_db.update(features_to_add, merge_strategy='error', id_spec='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print to file\n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_UTRs_pelechano_max.gff', 'w') as outfile:\n",
    "    outfile.write('##gff-version 3\\n')\n",
    "    for feature in merged_db.all_features(order_by = ('seqid','start','featuretype')):\n",
    "         print(feature,file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_db.conn.close()    #when troubleshooting you may need to close the database before remaking it. \n",
    "\n",
    "#Makes UTRs parents\n",
    "for utr_3p in merged_db.features_of_type('three_prime_UTR'):\n",
    "    gene_id = utr_3p.id.split('_')[0]\n",
    "    #print(gene_id)\n",
    "    #print(utr_3p.id)\n",
    " \n",
    "    try:\n",
    "        merged_db.add_relation(gene_id,utr_3p, 1, child_func = child_func, parent_func=parent_func)\n",
    "#        print(utr_3p.attributes)\n",
    "    except gffutils.FeatureNotFoundError:\n",
    "        print('There is no matching orf for the 3prime UTR ' + gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_tiftest.gff', 'w') as outfile:\n",
    "    outfile.write('##gff-version 3\\n')\n",
    "    for feature in merged_db.all_features(order_by = ('seqid','start','featuretype')):\n",
    "         print(feature,file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses merge_Nag_scer64.sh to \n",
    "#sort combined UTR and annotation file and then merges the coordinates of the UTR and previous gene to get new coordinates for gene. \n",
    "#with bedtools\n",
    "merge_cmd = ['/home/heineike/github/UTR_annotation/UTR_annotation/merge_Nag_scerR64.sh',\n",
    "             '/home/heineike/genomes/scer_20181114/saccharomyces_cerevisiae_R64-2-1_20150113']\n",
    "\n",
    "os.system(' '.join(merge_cmd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dict of coordinates that need to be changed\n",
    "merge_table = pd.read_table(genome_assy_dir+os.sep + sc_ref_base + '_nagdata_UTRchildren_merged', header = None)\n",
    "\n",
    "coord_change_dict = {}\n",
    "\n",
    "for row in merge_table.iterrows():\n",
    "    annotation = row[1][5]\n",
    "    annotation_ids = [item.split(\"=\")[1] for item in annotation.split(\";\") if item.split(\"=\")[0]==\"ID\"]\n",
    "    for ann_id in annotation_ids: \n",
    "        if '_' in ann_id:\n",
    "            if '3UTR' == ann_id.split('_')[1]:\n",
    "                gene_id = ann_id.split('_')[0]\n",
    "                coord_change = {}\n",
    "    \n",
    "                #for some reason the start coordinate for merged items on the + strand\n",
    "                #had one number subtracted in bedtools coord_change['start'] = row[1][1]+1\n",
    "                if row[1][3]=='+':\n",
    "                    coord_change['start'] = row[1][1]+1\n",
    "                elif row[1][3]=='-':\n",
    "                    coord_change['start'] = row[1][1]\n",
    "                coord_change['end'] = row[1][2]\n",
    "                coord_change['UTR_id'] = ann_id\n",
    "\n",
    "                coord_change_dict[gene_id] = coord_change\n",
    "\n",
    "\n",
    "#coord_change_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load new database that is sorted from bedtools\n",
    "#merged_sorted_db.conn.close()   #when troubleshooting may need to close database before reloading\n",
    "\n",
    "merged_sorted_fn = genome_assy_dir+os.sep + sc_ref_base + '_nagdata_UTRchildren_sorted.gff'\n",
    "\n",
    "\n",
    "merged_sorted_db = gffutils.create_db(merged_sorted_fn, dbfn=genome_assy_dir + os.sep + sc_ref_base + '_nagdata_UTRchildren_sorted.db', force=True, keep_order=True, \n",
    "                        merge_strategy='merge', sort_attribute_values=True)\n",
    "\n",
    "# merged_sorted_db.schema()\n",
    "# cursor = merged_sorted_db.execute(\"select id from features where seqid = 'I'\")\n",
    "# row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Chromosome name: chrmt.  New Chromosome name: Mito\n",
      "Old Chromosome name: chrIV.  New Chromosome name: IV\n",
      "Old Chromosome name: chrXIV.  New Chromosome name: XIV\n",
      "Old Chromosome name: chrXIII.  New Chromosome name: XIII\n",
      "Old Chromosome name: chrVIII.  New Chromosome name: VIII\n",
      "Old Chromosome name: chrXI.  New Chromosome name: XI\n",
      "Old Chromosome name: chrXV.  New Chromosome name: XV\n",
      "Old Chromosome name: chrX.  New Chromosome name: X\n",
      "Old Chromosome name: chrI.  New Chromosome name: I\n",
      "Old Chromosome name: chrIII.  New Chromosome name: III\n",
      "Old Chromosome name: chrXVI.  New Chromosome name: XVI\n",
      "Old Chromosome name: chrVII.  New Chromosome name: VII\n",
      "Old Chromosome name: chrXII.  New Chromosome name: XII\n",
      "Old Chromosome name: chrV.  New Chromosome name: V\n",
      "Old Chromosome name: chrVI.  New Chromosome name: VI\n",
      "Old Chromosome name: chrII.  New Chromosome name: II\n",
      "Old Chromosome name: chrIX.  New Chromosome name: IX\n"
     ]
    }
   ],
   "source": [
    "#renames all chromosomes to match the name that the SAM files from lexogen use. \n",
    "roman_numerals = ['I','II','III','IV','V','VI','VII','VIII','IX','X','XI','XII','XIII','XIV','XV','XVI']\n",
    "chromosome_rename_dict = {'chr' + num : num for num in roman_numerals} \n",
    "chromosome_rename_dict['chrmt']='Mito'\n",
    "\n",
    "for old_chr, new_chr in chromosome_rename_dict.items():\n",
    "    print('Old Chromosome name: ' + old_chr + '.  New Chromosome name: ' + new_chr)\n",
    "    merged_sorted_db.execute(\"update features set seqid='{}' where seqid='{}'\".format(new_chr, old_chr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update features set end=68527 where id = 'YNL299W'\n",
      "update features set end=509280 where id = 'YMR120C'\n",
      "update features set end=818438 where id = 'YOR262W'\n",
      "update features set end=744305 where id = 'YOR212W'\n",
      "update features set end=51002 where id = 'YBL089W'\n"
     ]
    }
   ],
   "source": [
    "#Moves start and end locations for each gene per new file\n",
    "jj = 0\n",
    "for gene_id, coord_change in coord_change_dict.items():\n",
    "    new_start = coord_change['start']\n",
    "    new_end = coord_change['end']\n",
    "    #prints out update statement every 1000 iterations. \n",
    "    jj = jj + 1\n",
    "    if jj==1000:\n",
    "        print(\"update features set end={} where id = '{}'\".format(new_end,gene_id))\n",
    "        jj = jj-1000\n",
    "    merged_sorted_db.execute(\"update features set start={} where id = '{}'\".format(new_start,gene_id))\n",
    "    merged_sorted_db.execute(\"update features set end={} where id = '{}'\".format(new_end,gene_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print to file\n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_UTRs.gff', 'w') as outfile:\n",
    "    outfile.write('##gff-version 3\\n')\n",
    "    for feature in merged_sorted_db.all_features():\n",
    "         print(feature,file=outfile)\n",
    "\n",
    "#In the backup file the child tag was at the end of many of the lines.  This most recent time I ran it, \n",
    "#the child tag was in the middle. Also the size was slightly different because the backup had windows CR LF instead of unix LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after the file was printed manually removed an open quote that was contained in line 22795:\n",
    "#line = 'XIV\tSGD\tgene\t555048\t556886\t.\t+\t.\tID=YNL039W;dbxref=SGD:S000004984;Name=YNL039W;Note=Essential subunit of RNA polymerase III transcription factor (TFIIIB)%3B TFIIIB is involved in transcription of genes encoding tRNAs%2C 5S rRNA%2C U6 snRNA%2C and other small RNAs;display=Essential subunit of RNA polymerase III transcription factor (TFIIIB);Ontology_term=GO:0000126,GO:0001026,GO:0001112,GO:0001156,GO:0070896,GO:0070898;orf_classification=Verified;child=YNL039W_3UTR;gene=BDP1;Alias=B\",BDP1,TFC5,TFC7,TFIIIB90,transcription factor TFIIIB subunit BDP1'\n",
    "#YNL039W, BDP1 changed B\" alias to Bprimeprime\n",
    "\n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_UTRs.gff', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(genome_assy_dir+os.sep + sc_ref_base + '_UTRs.gff', 'w') as f:\n",
    "    for line in lines:\n",
    "        if 'Alias=B\"' in line:\n",
    "            line_split = line.split('Alias=B\"')\n",
    "            line = line_split[0] + 'Alias=Bprimeprime' + line_split[1]\n",
    "        f.write(line)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the output looked good, commit and print to file\n",
    "merged_sorted_db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some useful commands to access / change data in gffutils. \n",
    "\n",
    "#db_id = 'YEL058W'\n",
    "#cursor = merged_db.execute('select * from features where id =\"%s\"' % db_id)\n",
    "#row = cursor.fetchone()\n",
    "#row['end']\n",
    "\n",
    "#feat = list(merged_db.features_of_type('three_prime_UTR'))[0]\n",
    "\n",
    "\n",
    "#pd.read_sql('select * from features;', merged_db.conn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
